<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Keras Gradient Based Post Training Quantization &mdash; MCT Documentation: ver 1.8.0</title>
      <link rel="stylesheet" href="../../../static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../static/documentation_options.js"></script>
        <script src="../../../static/doctools.js"></script>
        <script src="../../../static/sphinx_highlight.js"></script>
    <script src="../../../static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            MCT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guidelines/visualization.html">Visualization within TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guidelines/visualization.html#cosine-similarity-comparison">Cosine Similarity Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guidelines/visualization.html#mixed-precision-configuration-bit-width">Mixed-precision Configuration Bit-width</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guidelines/quickstart_keras.html">Quick start tutorial for Keras Post Training Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guidelines/quickstart_pytorch.html">Quick start tutorial for Pytorch Post Training Quantization</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MCT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Keras Gradient Based Post Training Quantization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../sources/api/experimental_api_docs/methods/keras_gradient_post_training_quantization_experimental.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="keras-gradient-based-post-training-quantization">
<span id="ug-keras-gradient-post-training-quantization-experimental"></span><h1>Keras Gradient Based Post Training Quantization<a class="headerlink" href="#keras-gradient-based-post-training-quantization" title="Permalink to this heading"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="model_compression_toolkit.gptq.keras_gradient_post_training_quantization_experimental">
<span class="sig-prename descclassname"><span class="pre">model_compression_toolkit.gptq.</span></span><span class="sig-name descname"><span class="pre">keras_gradient_post_training_quantization_experimental</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">representative_data_gen</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gptq_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gptq_representative_data_gen</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_kpi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">core_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">CoreConfig()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fw_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DEFAULT_KERAS_INFO</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_platform_capabilities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DEFAULT_KERAS_TPC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_experimental_exporter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_compression_toolkit.gptq.keras_gradient_post_training_quantization_experimental" title="Permalink to this definition"></a></dt>
<dd><p>Quantize a trained Keras model using post-training quantization. The model is quantized using a
symmetric constraint quantization thresholds (power of two).
The model is first optimized using several transformations (e.g. BatchNormalization folding to
preceding layers). Then, using a given dataset, statistics (e.g. min/max, histogram, etc.) are
being collected for each layer’s output (and input, depends on the quantization configuration).
For each possible bit width (per layer) a threshold is then being calculated using the collected
statistics. Then, if given a mixed precision config in the core_config, using an ILP solver we find
a mixed-precision configuration, and set a bit-width for each layer. The model is then quantized
(both coefficients and activations by default).
In order to limit the maximal model’s size, a target KPI need to be passed after weights_memory
is set (in bytes).
Then, the quantized weights are optimized using gradient based post
training quantization by comparing points between the float and quantized models, and minimizing the observed
loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">UserInformation</span></code>]</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>in_model</strong> (<em>Model</em>) – Keras model to quantize.</p></li>
<li><p><strong>representative_data_gen</strong> (<em>Callable</em>) – Dataset used for calibration.</p></li>
<li><p><strong>gptq_config</strong> (<a class="reference internal" href="../classes/GradientPTQConfig.html#model_compression_toolkit.gptq.GradientPTQConfigV2" title="model_compression_toolkit.gptq.GradientPTQConfigV2"><em>GradientPTQConfigV2</em></a>) – Configuration for using gptq (e.g. optimizer).</p></li>
<li><p><strong>gptq_representative_data_gen</strong> (<em>Callable</em>) – Dataset used for GPTQ training. If None defaults to representative_data_gen</p></li>
<li><p><strong>target_kpi</strong> (<a class="reference internal" href="../modules/mixed_precision_quantization_config.html#model_compression_toolkit.KPI" title="model_compression_toolkit.KPI"><em>KPI</em></a>) – KPI object to limit the search of the mixed-precision configuration as desired.</p></li>
<li><p><strong>core_config</strong> (<a class="reference internal" href="../modules/core_config.html#model_compression_toolkit.CoreConfig" title="model_compression_toolkit.CoreConfig"><em>CoreConfig</em></a>) – Configuration object containing parameters of how the model should be quantized, including mixed precision parameters.</p></li>
<li><p><strong>fw_info</strong> (<a class="reference internal" href="../classes/FrameworkInfo.html#model_compression_toolkit.FrameworkInfo" title="model_compression_toolkit.FrameworkInfo"><em>FrameworkInfo</em></a>) – Information needed for quantization about the specific framework (e.g., kernel channels indices, groups of layers by how they should be quantized, etc.). <a class="reference external" href="https://github.com/sony/model_optimization/blob/main/model_compression_toolkit/core/keras/default_framework_info.py">Default Keras info</a></p></li>
<li><p><strong>target_platform_capabilities</strong> (<a class="reference internal" href="../modules/target_platform.html#model_compression_toolkit.target_platform.TargetPlatformCapabilities" title="model_compression_toolkit.target_platform.TargetPlatformCapabilities"><em>TargetPlatformCapabilities</em></a>) – TargetPlatformCapabilities to optimize the Keras model according to.</p></li>
<li><p><strong>new_experimental_exporter</strong> (<em>bool</em>) – Whether exporting the quantized model using new exporter or not (in progress. Avoiding it for now is recommended).</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A quantized model and information the user may need to handle the quantized model.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Import a Keras model:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications.mobilenet</span> <span class="kn">import</span> <span class="n">MobileNet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MobileNet</span><span class="p">()</span>
</pre></div>
</div>
<p>Create a random dataset generator, for required number of calibration iterations (num_calibration_batches):
In this example a random dataset of 10 batches each containing 4 images is used.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_calibration_batches</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">repr_datagen</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_calibration_batches</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">yield</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))]</span>
</pre></div>
</div>
<p>Create an MCT core config, containing the quantization configuration:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">CoreConfig</span><span class="p">()</span>
</pre></div>
</div>
<p>If mixed precision is desired, create an MCT core config with a mixed-precision configuration, to quantize a model
with different bitwidths for different layers.
The candidates bitwidth for quantization should be defined in the target platform model:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">CoreConfig</span><span class="p">(</span><span class="n">mixed_precision_config</span><span class="o">=</span><span class="n">mct</span><span class="o">.</span><span class="n">MixedPrecisionQuantizationConfigV2</span><span class="p">(</span><span class="n">num_of_images</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>For mixed-precision set a target KPI object:
Create a KPI object to limit our returned model’s size. Note that this value affects only coefficients
that should be quantized (for example, the kernel of Conv2D in Keras will be affected by this value,
while the bias will not):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">kpi</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">KPI</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.75</span><span class="p">)</span>  <span class="c1"># About 0.75 of the model size when quantized with 8 bits.</span>
</pre></div>
</div>
<p>Create GPTQ config:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gptq_config</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">gptq</span><span class="o">.</span><span class="n">get_keras_gptq_config</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Pass the model with the representative dataset generator to get a quantized model:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">quantized_model</span><span class="p">,</span> <span class="n">quantization_info</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">gptq</span><span class="o">.</span><span class="n">keras_gradient_post_training_quantization_experimental</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">repr_datagen</span><span class="p">,</span> <span class="n">gptq_config</span><span class="p">,</span> <span class="n">target_kpi</span><span class="o">=</span><span class="n">kpi</span><span class="p">,</span> <span class="n">core_config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Sony Semiconductor Israel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>