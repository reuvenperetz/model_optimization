{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/reuvenperetz/model_optimization/blob/add_tf_notebook/tutorials/keras_notebook/keras_notebook.ipynb).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, you will see how to quantize a Keras model using MCT.\n",
    "More specifically:\n",
    "\n",
    "1. Train a simple `tf.keras` model for MNIST.\n",
    "2. Quantize the model to 8-bits model using MCT.\n",
    "3. Evaluate the models and compare results.\n",
    "\n",
    "This tutorial demonstrates a simple 8-bits quantization scheme. For more advanced quantization options, see the [API documentation](https://sony.github.io/model_optimization/api/api_docs/index.html).\n",
    "\n",
    "For more details, see [HPTQ](https://arxiv.org/abs/2109.09113).\n",
    "\n",
    "## Setup\n",
    "Install packages and import them:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install model-compression-toolkit\n",
    "! pip install -q tensorflow\n",
    "! pip install -q tensorflow-model-optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import model_compression_toolkit as mct\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a model for MNIST\n",
    "We will start by training a simple Keras model for MNIST.\n",
    "This code is based on a [Tensorflow tutorial](https://www.tensorflow.org/model_optimization/guide/quantization/training_example)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=1,\n",
    "  validation_split=0.1,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the pretrained model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, float_model_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Float model evaluation accuracy:', float_model_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quantize model using MCT\n",
    "\n",
    "First, MCT needs to retrieve a function to use in order to get images that represent\n",
    "the dataset the model was trained from for calibration purposes. The function should be called without any arguments, and should return a list numpy arrays (array for each\n",
    "model's input).\n",
    "\n",
    "Here for example, the model has a single input of a shape of [28 X 28 X 1] and we calibrate the model using batches of single images.\n",
    "Calling representative_data_gen() should return a list\n",
    "of a numpy.ndarray of shape [(1, 28, 28, 1)]."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def representative_data_gen() -> list:\n",
    "    sample = train_images[np.random.randint(0,len(train_images))]\n",
    "    return [np.expand_dims(sample, axis=0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can call keras_post_training_quantization from MCT to quantize the\n",
    "model to 8-bits model. By default, [keras_post_training_quantization](https://sony.github.io/model_optimization/api/api_docs/methods/keras_post_training_quantization.html#ug-keras-post-training-quantization) uses 500 iterations of statistics collection, but fewer iterations can be used:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_calibration_iterations = 1\n",
    "quantized_model, _ = mct.keras_post_training_quantization(model,\n",
    "                                                          representative_data_gen,\n",
    "                                                          n_iter=num_calibration_iterations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That is all! We got now a Keras model with quantized weights and activations.\n",
    "Note that the weights are fake-quantized and not integers, thus we approximate the expected model size.\n",
    "We can see that the expected model's size is ___ . Which is 4 times smaller than the original float model.\n",
    "Let's evaluate the quantized model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the digit classification model\n",
    "quantized_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "_, quantized_model_accuracy = quantized_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Quantized model evaluation accuracy:', quantized_model_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the accuracy was slightly dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_calibration_iterations = 1\n",
    "quantized_model, _ = mct.keras_post_training_quantization(model,\n",
    "                                                          representative_data_gen,\n",
    "                                                          n_iter=num_calibration_iterations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That is all! We got now a Keras model with quantized weights and activations.\n",
    "We can see that the expected model's size is ___ . Which is 4 times smaller than the original float model.\n",
    "Let's evaluate it:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the digit classification model\n",
    "quantized_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "_, quantized_model_accuracy = quantized_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Quantized model evaluation accuracy:', quantized_model_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the accuracy was dropped from __ to __ when the model size is X4 times smaller."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}