{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f31596-c293-4faa-8253-336769f8faa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quantization Aware Training using the Model Compression Toolkit - example in Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a972f-01a5-4b56-8ce7-ecfdb6daf942",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This tutorial will show how to use the Quantization Aware Training API of the Model Compression Toolkit. We will train a model on the MNIST dataset and quantize it with the Model Compression Toolkit QAT API.\n",
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/main/tutorials/notebooks/mct_features_notebooks/keras/example_keras_qat.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80481dd9-1e3c-4677-9d94-33f144ec540c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b380c492-3c53-4ec1-987e-de693a1ec1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_VER = '2.14.0'\n",
    "\n",
    "!pip install -q tensorflow=={TF_VER}\n",
    "! pip install -q mct-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49c27b1-65f9-4fd3-be3e-733f4c60124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import Model, layers, datasets\n",
    "import model_compression_toolkit as mct\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc817e1-5c21-4283-8ec8-8c2aff5feeea",
   "metadata": {
    "id": "fcc817e1-5c21-4283-8ec8-8c2aff5feeea"
   },
   "source": [
    "## Create TargetPlatformCapabilities\n",
    "For this tutorial, we will use a TargetPlatformCapabilities (TPC) with quantization of 2 bits for weights and 3 bits for activations.\n",
    "\n",
    "You can skip this part and use [get_target_platform_capabilities](https://sony.github.io/model_optimization/docs/api/api_docs/methods/get_target_platform_capabilities.html) to get an initilized TPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb6f84b-9775-4989-9f74-688958f3a1d3",
   "metadata": {
    "id": "8bb6f84b-9775-4989-9f74-688958f3a1d3"
   },
   "outputs": [],
   "source": [
    "from model_compression_toolkit import DefaultDict\n",
    "from model_compression_toolkit.target_platform_capabilities.target_platform.op_quantization_config import AttributeQuantizationConfig, Signedness\n",
    "from model_compression_toolkit.constants import FLOAT_BITWIDTH\n",
    "from model_compression_toolkit.target_platform_capabilities.constants import KERNEL_ATTR, KERAS_KERNEL, BIAS_ATTR, BIAS\n",
    "\n",
    "tp = mct.target_platform\n",
    "\n",
    "\n",
    "def get_tpc():\n",
    "    \"\"\"\n",
    "    Assuming a target hardware that uses a power-of-2 threshold for activations and\n",
    "    a symmetric threshold for the weights. The activations are quantized to 3 bits, and the kernel weights\n",
    "    are quantized to 2 bits. Our assumed hardware does not require quantization of some layers\n",
    "    (e.g. Flatten & Droupout).\n",
    "    This function generates a TargetPlatformCapabilities with the above specification.\n",
    "\n",
    "    Returns:\n",
    "         TargetPlatformCapabilities object\n",
    "    \"\"\"\n",
    "\n",
    "    # define a default quantization config for all non-specified weights attributes.\n",
    "    default_weight_attr_config = AttributeQuantizationConfig(\n",
    "        weights_quantization_method=tp.QuantizationMethod.POWER_OF_TWO,\n",
    "        weights_n_bits=8,\n",
    "        weights_per_channel_threshold=False,\n",
    "        enable_weights_quantization=False,\n",
    "        lut_values_bitwidth=None)\n",
    "\n",
    "    # define a quantization config to quantize the kernel (for layers where there is a kernel attribute).\n",
    "    kernel_base_config = AttributeQuantizationConfig(\n",
    "        weights_quantization_method=tp.QuantizationMethod.SYMMETRIC,\n",
    "        weights_n_bits=2,\n",
    "        weights_per_channel_threshold=True,\n",
    "        enable_weights_quantization=True,\n",
    "        lut_values_bitwidth=None)\n",
    "\n",
    "    # define a quantization config to quantize the bias (for layers where there is a bias attribute).\n",
    "    bias_config = AttributeQuantizationConfig(\n",
    "        weights_quantization_method=tp.QuantizationMethod.POWER_OF_TWO,\n",
    "        weights_n_bits=FLOAT_BITWIDTH,\n",
    "        weights_per_channel_threshold=False,\n",
    "        enable_weights_quantization=False,\n",
    "        lut_values_bitwidth=None)\n",
    "\n",
    "    # Create a default OpQuantizationConfig where we use default_weight_attr_config as the default\n",
    "    # AttributeQuantizationConfig for weights with no specific AttributeQuantizationConfig.\n",
    "    # MCT will compress a layer's kernel and bias according to the configurations that are\n",
    "    # set in KERNEL_ATTR and BIAS_ATTR that are passed in attr_weights_configs_mapping.\n",
    "    default_config = tp.OpQuantizationConfig(\n",
    "        default_weight_attr_config=default_weight_attr_config,\n",
    "        attr_weights_configs_mapping={KERNEL_ATTR: kernel_base_config,\n",
    "                                      BIAS_ATTR: bias_config},\n",
    "        activation_quantization_method=tp.QuantizationMethod.POWER_OF_TWO,\n",
    "        activation_n_bits=3,\n",
    "        supported_input_activation_n_bits=8,\n",
    "        enable_activation_quantization=True,\n",
    "        quantization_preserving=False,\n",
    "        fixed_scale=None,\n",
    "        fixed_zero_point=None,\n",
    "        simd_size=None,\n",
    "        signedness=Signedness.AUTO)\n",
    "\n",
    "    # Set default QuantizationConfigOptions in new TargetPlatformModel to be used when no other\n",
    "    # QuantizationConfigOptions is set for an OperatorsSet.\n",
    "    default_configuration_options = tp.QuantizationConfigOptions([default_config])\n",
    "    tp_model = tp.TargetPlatformModel(default_configuration_options)\n",
    "    with tp_model:\n",
    "        default_qco = tp.get_default_quantization_config_options()\n",
    "        # Group of OperatorsSets that should not be quantized.\n",
    "        tp.OperatorsSet(\"NoQuantization\",\n",
    "                        default_qco.clone_and_edit(enable_activation_quantization=False)\n",
    "                        .clone_and_edit_weight_attribute(enable_weights_quantization=False))\n",
    "        # Group of linear OperatorsSets such as convolution and matmul.\n",
    "        tp.OperatorsSet(\"LinearOp\")\n",
    "\n",
    "    tpc = tp.TargetPlatformCapabilities(tp_model)\n",
    "    with tpc:\n",
    "        # No need to quantize Flatten and Dropout layers\n",
    "        tp.OperationsSetToLayers(\"NoQuantization\", [layers.Flatten, layers.Dropout])\n",
    "        # Assign the framework layers' attributes to KERNEL_ATTR and BIAS_ATTR that were used during creation\n",
    "        # of the default OpQuantizationConfig.\n",
    "        tp.OperationsSetToLayers(\"LinearOp\", [layers.Dense, layers.Conv2D],\n",
    "                                 attr_mapping={KERNEL_ATTR: DefaultDict(default_value=KERAS_KERNEL),\n",
    "                                               BIAS_ATTR: DefaultDict(default_value=BIAS)})\n",
    "    return tpc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c811e-cba8-44f3-888f-e7452a68087d",
   "metadata": {},
   "source": [
    "## Init Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ff5ae-4474-4876-835f-ab2a2bbcb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "_input = layers.Input(shape=input_shape)\n",
    "x = layers.Conv2D(16, 3, strides=2, padding='same', activation='relu')(_input)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=_input, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094f140-f86a-4d76-9042-83a0c99a796e",
   "metadata": {},
   "source": [
    "## Init MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f2afd-0e80-4a80-86dd-1a26c7d3ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize images\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Add Channels axis to data\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ab0db-ec7d-4d55-9c52-3440289e4ae1",
   "metadata": {},
   "source": [
    "## Train a Keras classifier model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75d82e-e2a0-4204-a4b5-31263bc4b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train float model\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "# evaluate float model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Float model test accuracy: {score[1]:02.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0d525-4bc1-4958-ac67-d114bd25a001",
   "metadata": {},
   "source": [
    "## Prepare model for Hardware-Friendly Quantization Aware Training with MCT\n",
    "The MCT takes the float model and quantizes it in a post-training quantization fashion. The returned model contains trainable quantizers and is ready to be retrained (namely, a \"QAT ready\" model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c171d2d-6f0d-474d-aab6-22b0b0c9e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "\n",
    "\n",
    "def gen_representative_dataset():\n",
    "    def _generator():\n",
    "        for _ind in range(n_iter):\n",
    "            yield [x_train[_ind][np.newaxis, ...]]\n",
    "    return _generator\n",
    "\n",
    "\n",
    "qat_model, _, custom_objects = mct.qat.keras_quantization_aware_training_init_experimental(model,\n",
    "                                                                                           gen_representative_dataset(),\n",
    "                                                                                           core_config=mct.core.CoreConfig(),\n",
    "                                                                                           target_platform_capabilities=get_tpc())\n",
    "\n",
    "qat_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"], run_eagerly=True)\n",
    "score = qat_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"PTQ model test accuracy: {score[1]:02.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c74675-b4b5-42bd-a0b7-75da240cbf66",
   "metadata": {},
   "source": [
    "## User Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f1d23-9610-415a-84c2-8ef953370574",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "score = qat_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"QAT model test accuracy: {score[1]:02.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856de5a6-29d6-4e65-80b1-9f11ed63ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finalize QAT model: Remove QuantizeWrapper layers and leave only layers with quantized weights (FakeQuant values)\n",
    "quantized_model = mct.qat.keras_quantization_aware_training_finalize_experimental(qat_model)\n",
    "\n",
    "quantized_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Quantized model test accuracy: {score[1]:02.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856de5a6-29d6-4e65-80b1-9f11ed63ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantized model to Keras\n",
    "mct.exporter.keras_export_model(model=quantized_model, \n",
    "                                save_model_path='qmodel.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77d678-1fa7-4dc0-a6f3-bac10ba2d8ed",
   "metadata": {},
   "source": [
    "Copyright 2022 Sony Semiconductor Israel, Inc. All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
